{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af0e768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Synthetic dataset to be able to hide one ground truth to discover it\n",
    "\n",
    "Trajectory generation between two points is taken from the code from the paper:\n",
    "Diverse Trajectory Forecasting with Determinantal Point Processes\n",
    "Ye Yuan, Kris Kitani\n",
    "\n",
    "from the paper:\n",
    "- simulated vehicle behavior\n",
    "- add Gaussian noise to vehicle velocities\n",
    "- each data example (past, future) as 3 future steps and 2 past steps\n",
    "- Add an obstacle map around the current position to the context\n",
    "- total of 1100 training examples and 1000 test examples\n",
    "- road width is 2\n",
    "'''\n",
    "\n",
    "import errno\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed256004",
   "metadata": {},
   "source": [
    "## elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2676ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Trajectory:\n",
    "\n",
    "    def __init__(self, points, layout_name, path_name):\n",
    "        self.points = np.array(points)\n",
    "        self.layout = layout_name\n",
    "        self.pathname = path_name\n",
    "\n",
    "    def render(self, ax, clip=False):\n",
    "        x_values = list()\n",
    "        y_values = list()\n",
    "        pixel_pts = meters_to_pixels_traj(self.points, clip=clip)\n",
    "        \n",
    "        for p in pixel_pts:\n",
    "\n",
    "            x_values.append(p[0])\n",
    "            y_values.append(p[1])\n",
    "\n",
    "        ax.plot(x_values, y_values, lw=1, c='r', zorder=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb123f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Segment:\n",
    "    def __init__(self, spec):\n",
    "        self.sp = np.array(spec['sp'])\n",
    "        self.ep = np.array(spec['ep'])\n",
    "        self.ttraj = spec['ttraj']\n",
    "        self.mp = spec['mp']\n",
    "        self.theta = spec.get('theta')\n",
    "        self.inv = spec.get('inv')\n",
    "\n",
    "        self.pts = gen_points(self.sp, self.ep, self.ttraj, self.mp, self.theta, self.inv)\n",
    "\n",
    "        self.e_t = self.pts[-1] - self.pts[-2]\n",
    "        self.e_t = self.e_t / np.linalg.norm(self.e_t)\n",
    "        self.e_n = np.array([-self.e_t[1], self.e_t[0]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1615bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layout:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.name = config['name']\n",
    "        self.polygons = np.array(config['polygons'])\n",
    "\n",
    "    def render(self, ax):\n",
    "        pc = list()\n",
    "        for p in self.polygons:\n",
    "            polygon = Polygon(p, True, facecolor=[0.2, 0.2, 0.2])\n",
    "            pc.append(polygon)\n",
    "\n",
    "        all_patches = PatchCollection(pc)\n",
    "        ax.add_collection(all_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309d89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Path:\n",
    "    '''\n",
    "    ground truth\n",
    "    '''\n",
    "\n",
    "    def __init__(self, path_cfg):\n",
    "        self.layout = path_cfg['layout']\n",
    "        self.orientation = path_cfg['orientation']\n",
    "        self.speed = path_cfg['speed']\n",
    "        self.sp = np.array(path_cfg['sp'])\n",
    "\n",
    "        segs = list()\n",
    "        pts = list([self.sp])\n",
    "        for sspec in path_cfg['segments']:\n",
    "            seg = Segment(sspec)\n",
    "            pts.extend(seg.pts[1:])\n",
    "            segs.append(seg)\n",
    "\n",
    "        self.points = np.vstack(pts)\n",
    "        self.segments = segs\n",
    "        print(\"created paths in %s segments\" % len(self.segments))\n",
    "\n",
    "    def render(self, ax, clip=False):\n",
    "\n",
    "        print(f\"rendering path with points {self.points}\")\n",
    "        x_values = list()\n",
    "        y_values = list()\n",
    "\n",
    "        pixel_pts = meters_to_pixels_traj(self.points, clip=clip)\n",
    "\n",
    "        for p in pixel_pts:\n",
    "            x_values.append(p[0])\n",
    "            y_values.append(p[1])\n",
    "\n",
    "        print(f\"plotting the path with x {x_values} and y {y_values} points\")\n",
    "\n",
    "        ax.plot(x_values, y_values, lw=1, c='g', zorder=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3042a18",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cef3ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_points(sp, ep, ttraj, mp, theta=None, inv=None):\n",
    "    '''\n",
    "    generate intermediate points between start point sp and end point ep\n",
    "    line or arc depending on relation between sp and ep\n",
    "    function taken mostly from Yuan & Kitani\n",
    "\n",
    "    sp: start point\n",
    "    ep: end point\n",
    "    ttraj: type of trajectory (line or arc)\n",
    "    mp: number of intermediate points\n",
    "    theta: angle for arcs\n",
    "    inv: inversion for arcs\n",
    "    '''\n",
    "    pts = [sp.copy()]\n",
    "\n",
    "    # line between points (ez)\n",
    "    if ttraj == 'line':\n",
    "        d = (ep - sp) / (mp + 1)\n",
    "        for i in range(mp):\n",
    "            p = sp + d * (i + 1)\n",
    "            pts.append(p)\n",
    "\n",
    "    # arc between points\n",
    "    elif ttraj == 'arc':\n",
    "        theta = np.deg2rad(60)\n",
    "        a = (ep + sp) / 2\n",
    "        d = ep - sp\n",
    "        dist = np.linalg.norm(d)\n",
    "        d /= dist\n",
    "        e = np.array([-d[1], d[0]]) * (-1 if inv else 1)\n",
    "        c = a + e * (0.5 * dist / np.tan(theta / 2))\n",
    "        r = 0.5 * dist / np.sin(theta / 2)\n",
    "        t1 = np.arctan2(sp[1] - c[1], sp[0] - c[0])\n",
    "        t2 = np.arctan2(ep[1] - c[1], ep[0] - c[0])\n",
    "        dt = (t2 - t1) / (mp + 1)\n",
    "        for i in range(mp):\n",
    "            t = t1 + dt * (i + 1)\n",
    "            p = np.array([c[0] + r * np.cos(t), c[1] + r * np.sin(t)])\n",
    "            pts.append(p)\n",
    "\n",
    "    pts.append(ep.copy())\n",
    "    return pts\n",
    "\n",
    "\n",
    "def meters_to_pixels_traj(traj, clip=False):\n",
    "    '''\n",
    "    converts a matrix of points in relative meters (in the 14m x 14m grid centered on the vehicle with 4m behind, 10m forward and 7m each side) \n",
    "    to a point in pixels in a 224x224 grid with (0, 0) in the top left corner\n",
    "\n",
    "    TODO: make this function common to all datasets and manage the clip and the transformation matrix with the right dataset parameters instead of hardcoding\n",
    "    '''\n",
    "    shape = traj.shape\n",
    "    nostack = False\n",
    "    if len(shape) == 2:\n",
    "        nb_pts, dim = shape\n",
    "        all_traj = np.expand_dims(traj, 0)\n",
    "        nostack = True\n",
    "        nb_traj = 1\n",
    "    elif len(shape) == 3:\n",
    "        nb_traj, nb_pts, dim = traj.shape\n",
    "        all_traj = traj.copy()\n",
    "    else:\n",
    "        raise Exception(f\"unknown traj shape {shape}\")\n",
    "        \n",
    "    assert all_traj.shape == (nb_traj, nb_pts, dim)\n",
    "    \n",
    "    pixel_trajs = list()\n",
    "    for t in all_traj:\n",
    "        assert t.shape == (nb_pts, dim)\n",
    "        traj_2 = np.append(t, np.ones((nb_pts, 1)), axis=1)\n",
    "    \n",
    "        assert traj_2.shape == (nb_pts, 3)\n",
    "\n",
    "        hmatrix = np.array([[16, 0, 64], [0, 16, 112], [0, 0, 1]])\n",
    "        pixel_traj = np.matmul(hmatrix, np.transpose(traj_2))\n",
    "        pixel_traj = np.transpose(pixel_traj)\n",
    "        pixel_trajs.append(pixel_traj[:, 0:2])\n",
    "    \n",
    "    result = np.stack(pixel_trajs, 0)\n",
    "    if nostack:\n",
    "        result = result[0]\n",
    "\n",
    "    if clip:\n",
    "        result = np.clip(result, 0, 223)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def da_rendering(da, traj):\n",
    "    '''\n",
    "    renders a trajectory (as a collection of x,y points) on top of an image\n",
    "    both the image and the trajectory are from a top-left origin point\n",
    "    the trajectory should be in the pixel space (call meters_to_pixels_traj before if needed)\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(2.24, 2.24), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(da)\n",
    "    \n",
    "    traj_x = list()\n",
    "    traj_y = list()\n",
    "    for pt in traj:\n",
    "        traj_x.append(pt[0])\n",
    "        traj_y.append(pt[1])\n",
    "\n",
    "    ax.scatter(traj_x, traj_y, lw=1, c='r')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e83914",
   "metadata": {},
   "source": [
    "## Actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b517ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SynTrajDataset(Dataset):\n",
    "    '''\n",
    "    Synthetic trajectories dataset\n",
    "    - represents crossroads with several future possible trajectories\n",
    "    - one modality is systematically omitted (e.g. trajectories going left)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, config_path, split, omit=None):\n",
    "        '''\n",
    "        omit: the direction of the omitted direction in train\n",
    "        '''\n",
    "        assert split in ['train', 'test']\n",
    "        if split == 'train':\n",
    "            assert omit in ['left', 'right', 'straight']\n",
    "        else:\n",
    "            assert omit is None\n",
    "\n",
    "        if not os.path.isfile(config_path) and not config_path.startswith('/'):\n",
    "            alt_config_path = '../dataset/' + config_path\n",
    "            print(alt_config_path)\n",
    "\n",
    "            if os.path.isfile(alt_config_path):\n",
    "                config_path = alt_config_path\n",
    "            else:\n",
    "                raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), config_path)\n",
    "\n",
    "        # transformation matrix to go from trajectories in meters relative to the (O, O) to trajectories in pixel where (0, 0) is the top-left corner\n",
    "        self.trans_matrix = np.array([[16, 0, 64], [0, 16, 112], [0, 0, 1]])\n",
    "\n",
    "        self.layouts = {}    # name of the layout -> Layout object\n",
    "        self.paths = []\n",
    "        self.paths_per_layout = defaultdict(lambda: list())\n",
    "        self.config = yaml.safe_load(open(config_path, 'r'))\n",
    "        self.past_size = self.config['trajectory']['past_size']\n",
    "        self.future_size = self.config['trajectory']['future_size']\n",
    "        self.folder_path = os.path.sep.join(config_path.split(os.path.sep)[:-1])\n",
    "        print(f'considering folder path {self.folder_path}')\n",
    "\n",
    "        for layout in self.config['layouts']:\n",
    "            self.layouts[layout['name']] = Layout(layout)\n",
    "        for path in self.config['paths']:\n",
    "            p = Path(path)\n",
    "            self.paths.append(p)\n",
    "            self.paths_per_layout[p.layout].append(p.points)\n",
    "\n",
    "        # constraint on path depending on omit parameter\n",
    "        if split == 'train':\n",
    "            probs = np.array([(0.0 if p.orientation == omit else 1.0) for p in self.paths])\n",
    "        else:\n",
    "            probs = np.ones(len(self.paths))\n",
    "        self.pprobs = probs\n",
    "        # print(f\"probs {probs}\")\n",
    "\n",
    "        # layouts\n",
    "        self.size = np.array(self.config['pixel_size'])\n",
    "        self.layout_to_index = {name: i for i, name in enumerate(self.layouts.keys())}\n",
    "        self.nb_layouts = len(self.layouts)\n",
    "        self.layout_renders, self.drivable_areas, self.diffmaps, self.gradients = self.render_layouts()\n",
    "\n",
    "        self.trajs = self.gen_traj(int(self.config['trajectory']['n_train']), float(self.config['trajectory']['noise_n']))\n",
    "\n",
    "        # random order\n",
    "        rng = np.random.default_rng()\n",
    "        self.ex_order = np.arange(len(self.trajs))\n",
    "        rng.shuffle(self.ex_order)\n",
    "\n",
    "        self.preprocess = transforms.ToTensor()\n",
    "\n",
    "    def gen_traj(self, num, noise_n, balance=False):\n",
    "        trajs = []\n",
    "\n",
    "        # num = number of trajectories total\n",
    "        for i in range(num):\n",
    "            # pick a path\n",
    "            path = np.random.choice(self.paths, p=self.pprobs / self.pprobs.sum())\n",
    "\n",
    "            # print('picked path %s in %s' % (path.orientation, path.layout))\n",
    "            sp = path.points[0].copy()                  # start point of segment\n",
    "            sp[1] += noise_n * np.random.randn(1)       # add noise on start point\n",
    "            traj_pts = [sp]\n",
    "            # print(\"noised sp %s\" % str(sp))\n",
    "\n",
    "            # build trajectory by interpolating between noised waypoints of selected path\n",
    "            for seg in path.segments:\n",
    "\n",
    "                ep = seg.ep.copy()    # end point of segment\n",
    "                # print(\"ep %s\" % str(ep))\n",
    "\n",
    "                # add noise to end point\n",
    "                noise = np.clip(np.random.randn(2), -1.5, 1.5)\n",
    "                ep += seg.e_n * noise[1] * noise_n * 2.8    # noise scaling was 5.6 with previous 28x28 coordinates, now the coords are 14x14 meters so now it's 2.8\n",
    "                # print(\"noised ep %s\" % str(ep))\n",
    "\n",
    "                # generate points between start and end point\n",
    "                gen_pts = gen_points(sp, ep, seg.ttraj, seg.mp, seg.theta, seg.inv)\n",
    "\n",
    "                # add generated points to trajectory\n",
    "                traj_pts.extend(gen_pts[1:])\n",
    "\n",
    "                # print('new path points %s' % str(traj_pts))\n",
    "\n",
    "                sp = ep\n",
    "\n",
    "            # add traj to list\n",
    "            trajs.append(Trajectory(traj_pts, path.layout, path.orientation))\n",
    "\n",
    "        return trajs\n",
    "\n",
    "    def render(self, axs, draw_path=False, draw_traj=False, clip=True):\n",
    "        '''\n",
    "        rendering for viz only - all layouts are put on a single image\n",
    "        draw_path: do we draw each GT trajectory on the layouts\n",
    "        draw_traj: do we also draw all generated trajectories\n",
    "        '''\n",
    "\n",
    "        for i, (name, layout) in enumerate(self.layout_renders.items()):\n",
    "            axs[i].set_title(name)\n",
    "            # axs[i].axis([0, 224, 0, 224])\n",
    "            axs[i].imshow(layout, origin='upper')\n",
    "\n",
    "        if draw_path:\n",
    "            for path in self.paths:\n",
    "                index = self.layout_to_index[path.layout]\n",
    "                path.render(axs[index], clip=clip)\n",
    "        if draw_traj:\n",
    "            for traj in self.trajs:\n",
    "                index = self.layout_to_index[traj.layout]\n",
    "                traj.render(axs[index], clip=clip)\n",
    "\n",
    "    def render_layouts(self):\n",
    "        '''\n",
    "        get image of one layout\n",
    "        '''\n",
    "        layout_renders = dict()\n",
    "        drivable_areas = dict()\n",
    "        gradients = dict()\n",
    "        diffmaps = dict()\n",
    "\n",
    "        ax_range = self.config['range']\n",
    "\n",
    "        for name, layout in self.layouts.items():\n",
    "            figsize = self.size[:-1] / 100\n",
    "            fig = plt.figure(figsize=figsize, dpi=100)    # making a square figure so that the canvas is also square\n",
    "            ax = fig.add_subplot(111)\n",
    "            \n",
    "            rect = patches.Rectangle((ax_range[0], ax_range[2]), ax_range[1] - ax_range[0], ax_range[3] - ax_range[2],\n",
    "                                 facecolor=[0.9, 0.9, 0.9], zorder=0)\n",
    "            ax.set_aspect(1.0)\n",
    "            # ax.axis(ax_range)\n",
    "            ax.add_patch(rect)\n",
    "            ax.set_facecolor([0.9, 0.9, 0.9])\n",
    "\n",
    "            layout.render(ax)\n",
    "            \n",
    "            ax.axis('off')\n",
    "            fig.tight_layout(pad=0)\n",
    "            ax.margins(0)     # To remove the huge white borders\n",
    "\n",
    "            fig.canvas.draw()\n",
    "            image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            image_from_plot = image_from_plot.reshape(self.size)\n",
    "\n",
    "            layout_renders[name] = image_from_plot\n",
    "\n",
    "            # Binary DA map from layout\n",
    "            layout_image = image_from_plot.copy()\n",
    "            binary_layout = layout_image[:,:,0]\n",
    "            binary_layout[binary_layout != 230] = 255  # from blue (not road) and white (road) to 0 (road) and 1 (not road)\n",
    "            binary_layout[binary_layout == 230] = 0\n",
    "            drivable_areas[name] = binary_layout\n",
    "\n",
    "            # Diff map\n",
    "            diff_path = os.path.join(self.folder_path, f'diff_layout_{name}.png')\n",
    "            diffmap = ndimage.distance_transform_edt(binary_layout)\n",
    "            if not os.path.exists(diff_path):\n",
    "                diff_im = Image.fromarray(diffmap)\n",
    "                diff_im = diff_im.convert(\"L\")\n",
    "                diff_im.save(diff_path)\n",
    "\n",
    "            # gradients (we load again because taking diffmap directly doesn't work for some reason)\n",
    "            imgdiff = Image.open(diff_path)\n",
    "            npimg = np.asarray(imgdiff)\n",
    "            diffmaps[name] = npimg\n",
    "            g2 = np.gradient(npimg, edge_order=2)\n",
    "\n",
    "            gx2 = g2[0]\n",
    "            gy2 = g2[1]\n",
    "\n",
    "            gradients[name] = (gx2, gy2)\n",
    "\n",
    "        return layout_renders, drivable_areas, diffmaps, gradients\n",
    "\n",
    "    def render_example(self, axs, sample, clip=True):\n",
    "        '''\n",
    "        renders a specific example, not using the internals of the dataset rendering\n",
    "        this is mostly to check what the samples we generate look like from an external point of view (i.e. what the model will see)\n",
    "\n",
    "        example of use:\n",
    "        fig, axs = plt.subplots(1,5)\n",
    "        example = dataset_train[5]\n",
    "        dataset_train.render_example(axs, example)\n",
    "        plt.show()\n",
    "        '''\n",
    "        # first ax: layout + past and future trajectories\n",
    "        axs[0].imshow(sample['image'].permute(1, 2, 0))\n",
    "\n",
    "        past_x = list()\n",
    "        past_y = list()\n",
    "        future_x = list()\n",
    "        future_y = list()\n",
    "\n",
    "        past_pixels = meters_to_pixels_traj(sample['past_xy'], clip=clip)\n",
    "        future_pixels = meters_to_pixels_traj(sample['future_xy'], clip=clip)\n",
    "\n",
    "        for pp in past_pixels:\n",
    "            print(f'past traj point {pp[0]}')\n",
    "            past_x.append(pp[0])\n",
    "            past_y.append(pp[1])\n",
    "\n",
    "        axs[0].plot(past_x, past_y, lw=1, c='r')\n",
    "\n",
    "        for fp in future_pixels:\n",
    "            print(f'future traj point {fp}')\n",
    "            future_x.append(fp[0])\n",
    "            future_y.append(fp[1])\n",
    "\n",
    "        axs[0].plot(future_x, future_y, lw=1, c='g')\n",
    "\n",
    "        # da mask and diff map\n",
    "        axs[1].imshow(sample['da_mask'])\n",
    "        axs[2].imshow(sample['d_mask'])\n",
    "\n",
    "        # x and y gradients\n",
    "        axs[3].imshow(sample['dx_mask'])\n",
    "        axs[4].imshow(sample['dy_mask'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        only one int idx at a time\n",
    "        '''\n",
    "        traj = self.trajs[self.ex_order[idx]]\n",
    "\n",
    "        # past and future trajectories\n",
    "        past = np.array(traj.points[:self.past_size])\n",
    "        future = np.array(traj.points[self.past_size:])\n",
    "        info = {'path_orientation': traj.pathname, 'layout': traj.layout}\n",
    "\n",
    "        assert past.shape == (self.past_size, 2), 'got shape %s' % str(past.shape)\n",
    "        assert future.shape == (self.future_size, 2), 'got shape %s' % str(future.shape)\n",
    "\n",
    "        # layout map\n",
    "        layout_np = self.layout_renders[traj.layout]\n",
    "        input_tensor = self.preprocess(layout_np)\n",
    "        assert input_tensor.shape == (3, 224, 224), 'expected (3, 224, 224), got %s' % str(input_tensor.shape)\n",
    "\n",
    "        # diff and gradient maps and DA\n",
    "        npdiff = self.diffmaps[traj.layout]\n",
    "        npdt = torch.Tensor(npdiff)\n",
    "        npdx = self.gradients[traj.layout][0]\n",
    "        npdxt = torch.Tensor(npdx)\n",
    "        npdy = self.gradients[traj.layout][1]\n",
    "        npdyt = torch.Tensor(npdy)\n",
    "\n",
    "        da = torch.Tensor(self.drivable_areas[traj.layout])\n",
    "\n",
    "        sample = {'past_xy': past, 'future_xy': future, 'image': input_tensor, 'd_mask': npdt, 'dx_mask': npdxt, 'dy_mask': npdyt, 'da_mask': da, 'info': info}\n",
    "        # 'gt_paths': np.array(self.paths_per_layout[traj.layout])\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5805532",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f305f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'synthetic_relative.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add8fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "considering folder path /share/homes/lcalem/LSD/dataset\n",
      "created paths in 3 segments\n",
      "created paths in 2 segments\n",
      "created paths in 3 segments\n",
      "created paths in 3 segments\n",
      "created paths in 3 segments\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD0CAYAAACsLwv+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADOUlEQVR4nO3asXHCQBRFUctDE2SugYwaKIbUJZBSjGsgowYyyli3sIE88lydE7/gB7qziZYxxgfQ8Ln1AcB6BA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIOs8Ov759d/1L2uJ62PmHXzvfn1ids6nW7LDM7LzSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQELKMMaaG7/d7bgis7ng8LjM7LzSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQcpgdnu/Pv7zj33tcT1ufsGt7//5et8vUzgsNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQsY4ytbwBW4oWGEEFDiKAhRNAQImgIETSECBpCBA0hgoaQX++VHCx2NEm3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 224x224 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD0CAYAAACsLwv+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKElEQVR4nO3aMXHDQBRF0SgjIMHgzhgCRm0gpDWYYFBnDGaygRAV8mzm+px6i9fc+c0uY4w3oOF99gDgPIKGEEFDiKAhRNAQImgIETSECBpCBA0h69GHH18/L/2lbN8usye8tOvtPnvCVI/vz+XIOxcaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAhZjz7ct8szdwAncKEhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGkPXow+vt/swd/96+XWZPgD+50BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDyDLGmL0BOIkLDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIb/uBRNP7jbiEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 224x224 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_test = SynTrajDataset(config_path=config_path, split='test')\n",
    "# dataset_test = DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4254a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path_orientation': 'right', 'layout': 't-shaped'}\n",
      "past traj point 0.0\n",
      "past traj point 17.6\n",
      "past traj point 35.2\n",
      "past traj point 52.800000000000004\n",
      "future traj point [ 70.4        110.53366306]\n",
      "future traj point [ 96.59662868 117.89482766]\n",
      "future traj point [119.99541929 131.78535309]\n",
      "future traj point [139.00178292 151.25862298]\n",
      "future traj point [152.32046729 174.98756617]\n",
      "future traj point [153.66849817 191.25144554]\n",
      "future traj point [155.01652906 207.51532491]\n",
      "future traj point [156.36455994 223.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,5)\n",
    "example = dataset_test[5]\n",
    "print(example['info'])\n",
    "dataset_test.render_example(axs, example)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4bcff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
